{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21688e40-4566-47f6-8bf6-b1173d385ca6",
   "metadata": {},
   "source": [
    "# SC 16 - Plot to Plane: Working with NASA and NEON Airborne and Field Datasets\n",
    "\n",
    "### Ecological Society of America 2025 Conference In-Person Short Course\n",
    "\n",
    "#### SC 16 - Plot to Plane: Working with NASA and NEON Airborne and Field Datasets\n",
    "**Friday, August 15, 2025 - 8:00 AM – 11:00 AM EDT:**\n",
    "\n",
    "The contents of this tutorial were presented at an in-person Short Course held at the Ecological Society of America (ESA) 2025 Conference in Baltimore, Maryland.  Short Course participants had live coding experience within a Managed JupyterHub Service, supported by [2i2c](https://2i2c.org/) and by the [NASA Openscapes Community](https://nasa-openscapes.github.io/). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a39fb4b-1206-40fe-8cb1-28869f68db47",
   "metadata": {},
   "source": [
    "\n",
    "# Tutorial:  Mapping Invasive Species Using Supervised Machine Learning and AVIRIS-NG \n",
    "\n",
    "## Overview \n",
    "\n",
    "In October/November of 2023, the US National Aeronautics and Space Administration (NASA) conducted its first Biodiversity field and airborne campaign across terrestrial and aquatic environments in the South African Greater Cape Floristic Region (GCFR). From 4 airborne instruments (Airborne Visible-Infrared Imaging Spectrometer - Next Generation (AVIRIS-NG), Portable Remote Imaging SpectroMeter (PRISM), Hyperspectral Thermal Emission Spectrometer (HyTES), and Land, Vegetation, and Ice Sensor (LVIS)) the BioSCape Campaign’s remote sensing data products provides an unprecedented level of image spectroscopy from VSWIR to TIR wavelengths as well as full-waveform laser altimeter measurements. Airborne data are supplemented with a rich combination of contemporaneous biodiversity-relevant field observations toward an approach to measure and understand functional, phylogenetic, and taxonomic biological diversity as components of ecosystem function.\n",
    "\n",
    "In this notebook, we will use existing data of verified land cover and alien species locations to extract spectra from AVIRIS NG surface reflectance data.\n",
    "\n",
    "**Dataset**\n",
    "> Brodrick, P. G., Chlus, A. M., Eckert, R., Chapman, J. W., Eastwood, M., Geier, S., Helmlinger, M., Lundeen, S. R., Olson-Duvall, W., Pavlick, R., Rios, L. M., Thompson, D. R., & Green, R. O. (2025). BioSCape: AVIRIS-NG L3 Resampled Reflectance Mosaics, V2 (Version 1). ORNL Distributed Active Archive Center. https://doi.org/10.3334/ORNLDAAC/2427\n",
    "\n",
    " \n",
    "![final_class](images/fynbos_est_XGBOOST60.png)\n",
    "\n",
    "### Learning Objectives\n",
    "1. Understand how to inspect and prepare data for machine learning models\n",
    "2. Train and interpret a machine learning model\n",
    "3. Apply a trained model to AVIRIS imagery to create alien species maps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66219ca-026f-4dc5-a4ac-3abf1f59d50b",
   "metadata": {},
   "source": [
    "## Load Python Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce9f802-0a0b-4589-9a21-e562ae338e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modules imported separately - not available at the time of the workshop managed environment \n",
    "# !pip3 install --user xvec\n",
    "# !pip3 install --user shap\n",
    "# !pip3 install --user xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e71344-6b12-40c6-8d34-af2245dcd2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "import datetime as dt \n",
    "import geopandas as gpd\n",
    "import s3fs\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from shapely.geometry import box, mapping, Polygon, MultiPolygon\n",
    "import rioxarray as riox\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "import hvplot.xarray\n",
    "import holoviews as hv\n",
    "import xvec\n",
    "import shap\n",
    "import xgboost\n",
    "import matplotlib.pyplot as plt\n",
    "from dask.diagnostics import ProgressBar\n",
    "import warnings\n",
    "import earthaccess\n",
    "#our functions\n",
    "from utils import get_first_xr\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "hvplot.extension('bokeh')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061d90fc-5cdf-4ee6-912f-09167312586f",
   "metadata": {},
   "source": [
    "## Explore Sample Land Type Plot-Level Data\n",
    "For plot-level training data, we will use a small dataset over the Cape Town Peninsula of South Africa of manually collected invasive plant and land cover label\n",
    "- `ct_invasive.gpkg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd7ef19-7cd7-4e07-b67c-7d77ece5b102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's first create a DataFrame and assign labels to each class\n",
    "\n",
    "label_df = pd.DataFrame({'LandType': ['Bare ground/Rock','Mature Fynbos', \n",
    "              'Recently Burnt Fynbos', 'Wetland', \n",
    "              'Forest', 'Pine', 'Eucalyptus' , 'Wattle', 'Water'],\n",
    "               'class': ['0','1','2','3','4','5','6','7','8']})\n",
    "\n",
    "label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6332d4b6-6332-405a-85c7-a1e5618927d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's open the dataset, project to the South African UTM projection also used by the AVIRIS-NG airborne data, and merge it with the label data frame created above.\n",
    "class_data = gpd.read_file('ct_invasive.gpkg')\n",
    "# class_data.crs\n",
    "class_data_utm = (class_data\n",
    "                 .to_crs(\"EPSG:32734\")\n",
    "                 .merge(label_df, on='class', how='left')\n",
    "                 )\n",
    "class_data_utm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96d4b5a-316f-4092-936c-7cb027975f05",
   "metadata": {},
   "source": [
    "## Summarize and Visualize the Land Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e0f1b4-335c-4666-9e57-460a8387b2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the number of plots of each land type\n",
    "class_data_utm.groupby(['LandType']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443dca14-cc04-4644-b4a0-053527af8a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The group class will be used to determine training and test data\n",
    "class_data_utm.groupby(['group']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebddeb77-d922-4224-ad6a-7cdd0914dc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize the plot data in an interactive map, with color by class, using a Google satellite basemap\n",
    "class_data_utm[['LandType', 'geometry']].explore('LandType', tiles='https://mt1.google.com/vt/lyrs=s&x={x}&y={y}&z={z}', attr='Google')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95e3355-13ad-49a6-b98d-4557d9be02cc",
   "metadata": {},
   "source": [
    "## Earthdata Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeab0f30-cc5c-4d26-97cc-3f9407832b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ask for EDL credentials and persist them in a .netrc file\n",
    "auth = earthaccess.login(strategy=\"interactive\", persist=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4655f3-aa26-4a0f-80a5-3d79e4739702",
   "metadata": {},
   "source": [
    "## AVIRIS-NG Data over Cape Town Peninsula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480332f1-771d-4e93-8b37-bcc68e2fb92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search granules\n",
    "granules = earthaccess.search_data(\n",
    "    doi='10.3334/ORNLDAAC/2427', # BioSCape: AVIRIS-NG L3\n",
    "    granule_name = \"AVIRIS-NG*\", # exclude geojson tile\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d332f2-202a-4d9e-b0fd-6364a7965e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print one granule\n",
    "granules[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b603840-bf26-454b-ae42-42df1cd17d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars(granules[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd756db5-a3cc-421a-acad-2d307b34d3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_umm_geometry(gpoly):\n",
    "    \"\"\"converts UMM geometry to multipolygons\"\"\"\n",
    "    ltln = gpoly[0][\"Boundary\"][\"Points\"]\n",
    "    return Polygon([(p[\"Longitude\"], p[\"Latitude\"]) for p in ltln])\n",
    "\n",
    "def convert_list_gdf(datag):\n",
    "    \"\"\"converts List[] to geopandas dataframe\"\"\"\n",
    "    # create pandas dataframe from json\n",
    "    df = pd.json_normalize([vars(granule)['render_dict'] for granule in datag])\n",
    "    # keep only last string of the column names\n",
    "    df.columns=df.columns.str.split('.').str[-1]\n",
    "    # creates polygon geometry\n",
    "    df[\"geometry\"] = df[\"GPolygons\"].apply(convert_umm_geometry)\n",
    "    # return geopandas dataframe\n",
    "    return gpd.GeoDataFrame(df, geometry=\"geometry\", crs=\"EPSG:4326\")\n",
    "    \n",
    "AVNG_Coverage = convert_list_gdf(granules)\n",
    "AVNG_Coverage[['native-id', 'geometry']].explore(tiles='https://mt1.google.com/vt/lyrs=s&x={x}&y={y}&z={z}', attr='Google')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607cc880-a891-4f53-8d47-7885497be10f",
   "metadata": {},
   "source": [
    "## Open a single AVIRIS-NG Reflectance file to inspect the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa0e145-6eeb-4277-bbb6-0c4a813e722c",
   "metadata": {},
   "source": [
    "- **`xarray`** is an open source project and Python package that introduces labels in the form of dimensions, coordinates, and attributes on top of raw NumPy-like arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec57048b-c1cd-4c5d-83c2-8d6b954f1697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search granules that spatially intersects with class_data\n",
    "single_granule = earthaccess.search_data(\n",
    "    doi='10.3334/ORNLDAAC/2427', # BioSCape: AVIRIS-NG L3\n",
    "    granule_name = \"AVIRIS-NG_BIOSCAPE_V02_L3_36_11*\", # select only one file\n",
    ")\n",
    "single_granule[0].data_links(access=\"direct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86438d41-87d9-4d66-a40f-560e1b6d5d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# earthaccess open\n",
    "fh = earthaccess.open(single_granule)\n",
    "fh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7822767-8c06-4f8e-9b19-c28aacbb6104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_granule_type(fo):\n",
    "    \"\"\"separating granules by type\"\"\"\n",
    "    return ([f for f in fo if f.path.endswith(\"_RFL.nc\")],\n",
    "            [f for f in fo if f.path.endswith(\"_QL.tif\")],\n",
    "            [f for f in fo if f.path.endswith(\"_UNC.nc\")])\n",
    "rfl_f, ql_f, unc_f = separate_granule_type(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f66965-d621-4e25-b84f-0cc97ca3bf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a single file netcdf\n",
    "rfl_netcdf = xr.open_datatree(rfl_f[0],\n",
    "                              engine='h5netcdf', chunks={})\n",
    "rfl_netcdf = rfl_netcdf.reflectance.to_dataset()\n",
    "rfl_netcdf = rfl_netcdf.reflectance.where(rfl_netcdf.reflectance>0)\n",
    "rfl_netcdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a64646-2def-49ba-b833-cfd32e605911",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Plot just a red reflectance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b06cab1-2ca6-4a25-85b3-a88c24592fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = rfl_netcdf.sel({'wavelength': 660},method='nearest').hvplot('easting', 'northing',\n",
    "                                                      rasterize=True, data_aspect=1,\n",
    "                                                      cmap='magma',frame_width=400,clim=(0,0.3))\n",
    "h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfba3e0-fe9a-45fa-9a98-59fea321b78e",
   "metadata": {},
   "source": [
    "### Plot a quicklook image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b07c933-3009-408d-b8e0-e95d3e9e6a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a single file geotif\n",
    "ql_tif = xr.open_dataset(ql_f[0], engine='rasterio')\n",
    "h = ql_tif.hvplot.rgb('x', 'y', bands='band', rasterize=True, data_aspect=1, frame_width=400)\n",
    "h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d256e39-744b-467f-8fc0-519b02a41321",
   "metadata": {},
   "source": [
    "## Select the AVIRIS-NG Flight Line data to selected parameters\n",
    "For our analysis demonstration in this Notebook, we'll narrow the flight tiles to the area of the Cape Penisula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee41aa3-2ebc-4986-bd5d-accadffb1e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search granules that spatially intersects with class_data\n",
    "granules_cp = earthaccess.search_data(\n",
    "    doi='10.3334/ORNLDAAC/2427', # BioSCape: AVIRIS-NG L3\n",
    "    bounding_box = tuple(class_data.total_bounds),\n",
    "    granule_name = \"AVIRIS-NG*\", # exclude geojson tile\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a3ada3-cf4b-4371-9412-929088082851",
   "metadata": {},
   "outputs": [],
   "source": [
    "AVNG_Coverage = convert_list_gdf(granules_cp)\n",
    "AVNG_Coverage[['native-id', 'geometry']].explore('native-id', tiles='https://mt1.google.com/vt/lyrs=s&x={x}&y={y}&z={z}', attr='Google')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73ef8ca-1f8b-4e85-913c-219adf1ebf7d",
   "metadata": {},
   "source": [
    "### Extract Spectra for each Land Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775b10c6-0ffa-42d7-a009-d9f0ba237c54",
   "metadata": {},
   "source": [
    "Now that we are familiar with the data, we want to get the AVIRIS spectra at each label location. Below is a function that does this and returns the result as a xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36321f50-3c41-4e9b-b8fb-c50abc8738c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_cp = earthaccess.open(granules_cp)\n",
    "rfl_f, ql_f, unc_f = separate_granule_type(f_cp)\n",
    "AVNG_CP = AVNG_Coverage.to_crs(\"EPSG:32734\")\n",
    "ds_all =[]\n",
    "for rfl in rfl_f:\n",
    "    native_id = path.basename(rfl.path)[:-7]\n",
    "    geof = AVNG_CP[AVNG_CP[\"native-id\"]==native_id].geometry\n",
    "    points = class_data_utm.clip(geof)\n",
    "    n_points = points.shape[0]\n",
    "    if n_points:\n",
    "        print(f'got {n_points} point from {native_id}')\n",
    "        ds = xr.open_datatree(rfl, engine='h5netcdf', chunks={})\n",
    "        points = points.to_crs(ds.transverse_mercator.crs_wkt)\n",
    "        ds_all.append(ds.reflectance.to_dataset().xvec.extract_points(points['geometry'], \n",
    "                                                                x_coords=\"easting\", \n",
    "                                                                y_coords=\"northing\",\n",
    "                                                                index=True))\n",
    "ds_all = xr.concat(ds_all, dim='file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89d9db1-29c4-4d57-86c9-aa93ab207bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77493f79-8baf-487c-be8f-21789b992236",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = get_first_xr(ds_all)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895b4f9b-842a-43aa-9226-cb20c1106c17",
   "metadata": {},
   "source": [
    "This data set just has the spectra. We need to merge with point data to add labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea14253-bf16-42ba-a2eb-712634cac76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_xr =class_data_utm[['class','group']].to_xarray()\n",
    "ds = ds.merge(class_xr.astype(int),join='left')\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19eff926-f01d-4856-91ea-02b81572948b",
   "metadata": {},
   "source": [
    "We have defined all the operations we want, but becasue of xarrays lazy computation, the calculations have not yet been done. We will now force it to perform this calculations. We want to keep the result in chunks, so we use .persist() and not .compute(). This should take approx 2 - 3 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1f1e08-dbed-4329-9777-7957ceef389f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  DUE TO RUN TIME LENGTH, WE WILL NOT RUN THIS IN THE WORKSHOP - For this workshop, we HAVE SAVED THIS OUTPUT (dsp.nc) and it is available FOR NEXT STEP\n",
    "# with ProgressBar():\n",
    "#     dsp = ds.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318d800d-ad44-4840-a218-f055d1dfb389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dsp.drop_vars('geometry').to_netcdf('~/shared-public/data/dsp.nc')\n",
    "dsp = xr.open_dataset('dsp.nc')\n",
    "dsp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7620adb-7dd3-44c7-99e6-03216d0c5c96",
   "metadata": {},
   "source": [
    "### Inspect AVIRIS spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca9c4ea-12ac-4718-867d-9b9953c2ade1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall the class types\n",
    "label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0332b5-3eb5-4cc0-8860-c764f03f33b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsp_plot = dsp.where(dsp['class']==5, drop=True)\n",
    "h = dsp_plot['reflectance'].hvplot.line(x='wavelength',by='index',\n",
    "                                    color='green', alpha=0.5,legend=False)\n",
    "h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fd3b5e-e390-4eb5-9b21-ede5fdaddced",
   "metadata": {},
   "source": [
    "> At this point in a real machine learning workflow, you should closely inspect the spectra you have for each class. Do they make sense? Are there some spectra that look weird? You should re-evaluate your data to make sure that the assigned labels are true. This is a very important step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2781095e-98e8-4a72-90b6-c2f0a0bd664c",
   "metadata": {},
   "source": [
    "#### Prep data for ML model\n",
    "\n",
    "As you will know, not all of the wavelengths in the data are of equal quality, some will be degraded by atmospheric water absorption features or other factors. We should remove the bands from the analysis that we are not confident of. Probably the best way to do this is to use the uncertainties provided along with the reflectance files. We will simply use some prior knowledge to screen out the worst bands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ef2ccf-025a-43fc-8148-b224c13d42b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelengths_to_drop = dsp.wavelength.where(\n",
    "    (dsp.wavelength < 450) |\n",
    "    (dsp.wavelength >= 1340) & (dsp.wavelength <= 1480) |\n",
    "    (dsp.wavelength >= 1800) & (dsp.wavelength <= 1980) |\n",
    "    (dsp.wavelength > 2400), drop=True\n",
    ")\n",
    "\n",
    "# Use drop_sel() to remove those specific wavelength ranges\n",
    "dsp = dsp.drop_sel(wavelength=wavelengths_to_drop)\n",
    "\n",
    "mask = (dsp['reflectance'] > -1).all(dim='wavelength')  # Create a mask where all values along 'z' are non-negative\n",
    "dsp = dsp.sel(index=mask)\n",
    "dsp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85b58ab-66b1-4559-b3fd-0da97abbf06b",
   "metadata": {},
   "source": [
    "Next we will normalize the data, there are a number of difference normalizations to try. In a ML workflow you should try a few and see which work best. We will only use a **`Brightness Normalization`**. In essence, we scale the reflectance of each wavelength by the total brightness of the spectra. \n",
    "\n",
    "In applications like hyperspectral imaging or spectral data analysis, brightness normalization helps eliminate differences caused by varying magnitudes of the reflectance. This ensures that the analysis of spectral features focuses entirely on the shape or characteristics of the spectra, independent of overall brightness or intensity.\n",
    "\n",
    "The reflectance values are scaled to create a consistent baseline for comparing spectra or features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86886370-d346-4547-8db4-4a7b27e479aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the L2 norm along the 'wavelength' dimension\n",
    "l2_norm = np.sqrt((dsp['reflectance'] ** 2).sum(dim='wavelength'))  # the square root of the sum of the squares of the values across dim wavelength\n",
    "\n",
    "# Normalize the reflectance by dividing by the L2 norm\n",
    "dsp['reflectance'] = dsp['reflectance'] / l2_norm  # removes brightness differences due to varying magnitudes and ensures that \n",
    "                                                   # the reflectance values across wavelengths are unit-normalized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53e157b-1e16-4a64-bb68-037a450c5585",
   "metadata": {},
   "source": [
    "Plot the new, clean spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdea565b-f455-4aa3-8f76-ca6ae28d00fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsp_norm_plot = dsp.where(dsp['class']==5, drop=True)\n",
    "h = dsp_norm_plot['reflectance'].hvplot.line(x='wavelength',by='index',\n",
    "                                         color='green',ylim=(-0.01,0.15),alpha=0.5,legend=False)\n",
    "h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38ac6b4-711a-4322-9209-e1d82345f232",
   "metadata": {},
   "source": [
    "### Train and evaluate the ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8628a508-5f72-429e-9fb1-09a441a2ec20",
   "metadata": {},
   "source": [
    "We will be using a model called **`xgboost`**. There are many different kinds of ML models. `xgboost`, or Extreme Gradient Boosting, is a class of models called gradient boosted trees, related to random forests. When used for classification, random forests work by creating multiple decision trees, each trained on a random subset of the data and features, and then averaging their predictions to improve accuracy and reduce overfitting. \n",
    "\n",
    "Gradient boosted trees differ in that they build trees sequentially, with each new tree focusing on correcting the errors of the previous ones. This sequential approach allows `xgboost` to create highly accurate models by iteratively refining predictions and addressing the weaknesses of earlier trees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bca1ea9-9cb3-427b-abaa-7ecbf237c5af",
   "metadata": {},
   "source": [
    "Import the Machine Learning libraries we will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e9f2ba-072d-4f51-8314-8c002dd60803",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013634d9-b759-450d-a7b8-80b41b171bb1",
   "metadata": {},
   "source": [
    "Our dataset has a label indicating which set (training or test), our data belong to. We wil use this to split it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2d3cff-1402-4415-bb9e-23e634ffdc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall groups\n",
    "class_data_utm.groupby(['group']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812a85a0-2788-4b70-be09-b4ab315358be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_data_utm.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2475030c-18c1-49c0-b1b9-363fac87cb10",
   "metadata": {},
   "source": [
    "Let's separate the data into training and testing subsets for model training and evaluation, respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d2c637-fd44-47ad-8c3d-c29510b3c4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = dsp.where(dsp['group']==1,drop=True)  # the training set\n",
    "dtest = dsp.where(dsp['group']==2,drop=True)   # the evaluation (testing) set\n",
    "\n",
    "#create separte datasets for labels and features\n",
    "y_train = dtrain['class'].values.astype(int)  # the variable 'class' is extracted from both the training (dtrain) and testing (dtest) datasets\n",
    "y_test = dtest['class'].values.astype(int)\n",
    "X_train = dtrain['reflectance'].values        # The variable 'reflectance' is extracted from both the training (dtrain) and testing (dtest) datasets\n",
    "X_test = dtest['reflectance'].values          # .values: Converts the 'reflectance' variable into a NumPy array for the machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f993d6-bed9-4f71-83b5-1a50c9034fb6",
   "metadata": {},
   "source": [
    "#### Train ML model\n",
    "The steps we will go through to train the model are:\n",
    "\n",
    "- First, we define the hyperparameter grid. Initially, we set up a comprehensive grid (param_grid) with multiple values for several hyperparameters of the XGBoost model. \n",
    "\n",
    "- Next, we create an XGBoost classifier object using the XGBClassifier class from the XGBoost library.\n",
    "\n",
    "We then set up the GridSearchCV object using our defined XGBoost model and the hyperparameter grid. GridSearchCV allows us to perform an exhaustive search over the specified hyperparameter values to find the optimal combination that results in the best model performance. We choose a 5-fold cross-validation strategy (cv=5), meaning we split our training data into five subsets to validate the model's performance across different data splits. We use accuracy as our scoring metric to evaluate the models.\n",
    "\n",
    "After setting up the grid search, we fit the GridSearchCV object to our training data (X_train and y_train). This process involves training multiple models with different hyperparameter combinations and evaluating their performance using cross-validation. Our goal is to identify the set of hyperparameters that yields the highest accuracy.\n",
    "\n",
    "Once the grid search completes, we print out the best set of hyperparameters and the corresponding best score. The grid_search.best_params_ attribute provides the combination of hyperparameters that achieved the highest cross-validation accuracy, while the grid_search.best_score_ attribute shows the corresponding accuracy score. Finally, we extract the best model (best_model) from the grid search results. This model is trained with the optimal hyperparameters and is ready for making predictions or further analysis in our classification task.\n",
    "\n",
    "This will take approx __30 seconds__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d617f51d-b299-4c9b-810a-962cd8fa303a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameter grid\n",
    "param_grid = {                   # param_grid dictionary specifies the hyperparameters to be tuned and the values to be tested for each hyperparameter\n",
    "    'max_depth': [5],            # maximum depth of a tree, controlling the complexity of the individual tree\n",
    "    'learning_rate': [0.1],      # rate at which the model updates weights during training\n",
    "    'subsample': [0.75],         # fraction of the training data to randomly sample for each tree\n",
    "    'n_estimators' : [50,100]    # number of boosting rounds (trees) in the ensemble\n",
    "}\n",
    "\n",
    "# Create the XGBoost model object\n",
    "xgb_model = xgb.XGBClassifier(tree_method='hist')\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(xgb_model, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best set of hyperparameters and the corresponding score\n",
    "print(\"Best set of hyperparameters: \", grid_search.best_params_)  # the combination of hyperparameters that achieved the highest accuracy during cross-validation\n",
    "print(\"Best score: \", grid_search.best_score_)    # the cross-validation accuracy score corresponding to the best hyperparameters\n",
    "best_model = grid_search.best_estimator_    # Retrieves the trained model (XGBoost classifier) corresponding to the best combination of hyperparameters \n",
    "                                            # found during the grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8562cfe4-e227-4f64-bb01-4b19f4667e35",
   "metadata": {},
   "source": [
    "### Evaluate model performance\n",
    "\n",
    "We will use our best model to predict the classes of the test data  Then, we calculate the F1 score using f1_score, which balances precision and recall, and print it to evaluate overall performance.\n",
    "\n",
    "Next, we assess how well the model performs for predicting Pine trees by calculating its precision and recall. Precision measures the accuracy of the positive predictions.  It answers the question, \"Of all the instances we labeled as Pines, how many were actually Pines?\". Recall measures the model's ability to identify all actual positive instances. It answers the question, \"Of all the actual Pines, how many did we correctly identify?\". You may also be familiar with the terms Users' and Producers' Accuracy. Precision  = User' Accuracy, and Recall = Producers' Accuracy.\n",
    "\n",
    "Finally, we create and display a confusion matrix to visualize the model's prediction accuracy across all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae338166-20e3-4d20-92a5-e820ad0ee74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97ca76e-2c9e-4d4c-a451-c3df092adc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Step 2: Calculate acc and F1 score for the entire dataset\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {acc}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')  # 'weighted' accounts for class imbalance\n",
    "print(f\"F1 Score (weighted): {f1}\")\n",
    "\n",
    "# Step 3: Calculate precision and recall for class 6 (Eucalyptus)\n",
    "precision_class_6 = precision_score(y_test, y_pred, labels=[6], average='macro', zero_division=0)\n",
    "recall_class_6 = recall_score(y_test, y_pred, labels=[6], average='macro', zero_division=0)\n",
    "\n",
    "print(f\"Precision for Class 6: {precision_class_6}\")\n",
    "print(f\"Recall for Class 6: {recall_class_6}\")\n",
    "\n",
    "# Step 4: Plot the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "ConfusionMatrixDisplay(confusion_matrix=conf_matrix).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af6cd27-1fcc-4119-90a2-188e2acf5d72",
   "metadata": {},
   "source": [
    "- `Accuracy` provides a general measure of how well the classifier performs overall\n",
    "    - It is the Number of Correct Predictions divided by the Total Number of Samples\n",
    "- `Precision` measures the proportion of true positive predictions relative to the total predicted positives for a class\n",
    "- `Confusion Matrix` Computes the matrix summarizing the classifier’s predictions. Each row corresponds to the true label, and each column corresponds to the predicted label. The diagonal elements represent correctly classified samples, while off-diagonal elements represent misclassifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86524208-33fd-4935-b623-275427972b27",
   "metadata": {},
   "source": [
    "### Predict over an example AVIRIS scene\n",
    "\n",
    "We now have a trained model and are ready to deploy it to generate predictions across an entire AVIRIS scene and map the distribution of invasive plants. This involves handling a large volume of data, so we need to write the code to do this intelligently. We will accomplish this by applying the `.predict()` method of our trained model in parallel across the chunks of the AVIRIS xarray. The model will receive one chunk at a time so that the data is not too large, but it will be able to perform this operation in parallel across multiple chunks, and therefore will not take too long."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ed9114-93ed-410b-9c41-84ab106f0efe",
   "metadata": {},
   "source": [
    "This model was only trained on data covering natural vegetaton in the Cape Peninsula, It is important that we only predict in the areas that match our training data. We will therefore filter to scenes that cover the Cape Peninsula."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ed40f0-2b5e-4970-8493-082f38a2de93",
   "metadata": {},
   "source": [
    "Here is the function that we will actually apply to each chunk. Simple really. The hard work is getting the data into and out of this function\n",
    "- `chunk` - a portion of input data (e.g., a subset of the dataset) The function processes chunks for efficient computation and prediction\n",
    "- `model` - This is our trained machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0158fee1-4b09-4999-acfd-f5c4dd8ed19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_chunk(chunk, model):\n",
    "    probabilities = model.predict_proba(chunk)\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2d8e1b-c32d-4911-9a7c-21f6cfa449e2",
   "metadata": {},
   "source": [
    "Now we define the funciton that takes as input the path to the AVIRIS file and pass the data to the predict function. This is composed of 4 parts:\n",
    "\n",
    "- Part 1: Opens the AVIRIS data file using xarray and sets a condition to identify valid data points where reflectance values are greater than zero.\n",
    "\n",
    "- Part 2: Applies all the transformations that need to be done before the data goes to the model. It puts the spatial dimensions (x and y) into a single dimension, filters wavelengths, and normalizes the reflectance data.\n",
    "\n",
    "- Part 3: Applies the machine learning model to the normalized data in parallel, predicting class probabilities for each data point using xarray's apply_ufunc method. Most of the function invloves defining what to do with the dimensions of the old dataset and the new output\n",
    "\n",
    "- Part 4: Unstacks the data to restore its original dimensions, sets spatial dimensions and coordinate reference system (CRS), clips the data, and transposes the data to match expected formats before returning the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed0c90c-c056-4637-9945-a6a4d21af109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_xr(file,geometries):\n",
    "\n",
    "    rfl_f, ql_f, unc_f = separate_granule_type(file)\n",
    "    native_id = path.basename(rfl_f[0].path)[:-7]\n",
    "    \n",
    "    #part 1 - opening file\n",
    "    #open the file\n",
    "    print(f'file: {rfl_f[0]}')\n",
    "    ds = xr.open_datatree(rfl_f[0], engine='h5netcdf', chunks='auto')\n",
    "    \n",
    "    #get the geometries of the protected areas for masking\n",
    "    ds_crs = ds.transverse_mercator.crs_wkt\n",
    "    geometries = geometries[geometries[\"native-id\"]==native_id].to_crs(ds_crs).geometry.apply(mapping)\n",
    "    # geometries = geometries.to_crs(ds_crs).geometry.apply(mapping)\n",
    "    \n",
    "    #condition to use for masking no data later\n",
    "    condition = (ds['reflectance'] > -1).any(dim='wavelength')\n",
    "    \n",
    "    #stack the data into a single dimension. This will be important for applying the model later\n",
    "    ds = ds.reflectance.to_dataset().stack(sample=('easting','northing'))\n",
    "    \n",
    "    #part 2 - pre-processing\n",
    "    #remove bad wavelenghts\n",
    "    wavelengths_to_drop = ds.wavelength.where(\n",
    "        (ds.wavelength < 450) |\n",
    "        (ds.wavelength >= 1340) & (ds.wavelength <= 1480) |\n",
    "        (ds.wavelength >= 1800) & (ds.wavelength <= 1980) |\n",
    "        (ds.wavelength > 2400), drop=True\n",
    "    )\n",
    "    # Use drop_sel() to remove those specific wavelength ranges\n",
    "    ds = ds.drop_sel(wavelength=wavelengths_to_drop)\n",
    "    \n",
    "    #normalise the AVIRIS data\n",
    "    l2_norm = np.sqrt((ds['reflectance'] ** 2).sum(dim='wavelength'))\n",
    "    ds['reflectance'] = ds['reflectance'] / l2_norm\n",
    "    \n",
    "     \n",
    "    #part 3 - apply the model over chunks\n",
    "    result = xr.apply_ufunc(\n",
    "        predict_on_chunk,\n",
    "        ds['reflectance'].chunk(dict(wavelength=-1)),\n",
    "        input_core_dims=[['wavelength']],    # input dim with features\n",
    "        output_core_dims=[['class']],        # name for the new output dim\n",
    "        exclude_dims=set(('wavelength',)),   # dims to drop in result\n",
    "        output_sizes={'class': 9},           # length of the new dimension\n",
    "        output_dtypes=[np.float32],\n",
    "        dask=\"parallelized\",\n",
    "        kwargs={'model': best_model}\n",
    "    )\n",
    "    \n",
    "    #part 4 - post-processing\n",
    "    result = result.where((result >= 0) & (result <= 1), np.nan)  # valid values\n",
    "    result = result.unstack('sample')                             # remove the stack\n",
    "    result = result.rio.set_spatial_dims(x_dim='easting',y_dim='northing') # set the spatial dims\n",
    "    result = result.rio.write_crs(ds_crs)                         # set the CRS\n",
    "    result = result.rio.clip(geometries)                          # clip to the protected areas and no data\n",
    "    result = result.transpose('class', 'northing', 'easting')     # transpose the data - rio expects it this way\n",
    "    \n",
    "    return result   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e193e979-e2a5-4d88-bd81-ac0cd8f8577c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ed10603-660c-49cd-a40c-1702201631b8",
   "metadata": {},
   "source": [
    "Let's test that it works on a single file before we run it through 100s of GB of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb17f14-5cf0-4684-a293-02db53dd3b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test  = predict_xr(earthaccess.open(single_granule),AVNG_sapad)\n",
    "test  = predict_xr(earthaccess.open(single_granule),AVNG_Coverage)\n",
    "#test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cd85d4-4c17-4b62-a44f-f11b62c0778a",
   "metadata": {},
   "source": [
    "The AVIRIS tile is **AVIRIS-NG_BIOSCAPE_V02_L3_36_11_RFL.nc**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faec501e-747c-41f9-a301-eebdf58319d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, recall the labels and LandType classes\n",
    "label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf72047-9ef4-429e-8e91-10ec4781933e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproject the dataset to WGS84 (EPSG:4326)\n",
    "test = test.rio.reproject(\"EPSG:4326\", nodata=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d802acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Enhanced Plot with Titles and Styling\n",
    "h = test.isel({'class': 1}).hvplot(\n",
    "    tiles=hv.element.tiles.EsriImagery(),   # Use Esri Imagery as a tile background\n",
    "    project=True,                          # Project the data to work seamlessly with the background\n",
    "    rasterize=True,                        # Rasterize for efficient plotting\n",
    "    clim=(0.01, 1),                           # Define color limits to focus on the range of interest\n",
    "    cmap='magma',                          # Colormap for better visualization\n",
    "    frame_width=800,                       # Increase the width for better spatial resolution\n",
    "    data_aspect=1,                         # Maintain a realistic and proportional aspect ratio\n",
    "    alpha=0.5,                             # Adjust opacity for optimal visualization\n",
    "    colorbar=True                          # Enable the colorbar (hvplot handles this properly)\n",
    ")\n",
    "\n",
    "# Add Descriptive Titles (handled internally by hvplot)\n",
    "h = h.opts(\n",
    "    title=\"Class 1: Mature Fynbos - Probability Mapping\"  # Set title directly using Holoviews options\n",
    ")\n",
    "h \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cbe64a-fc6b-427b-bb72-cf13ab4259b7",
   "metadata": {},
   "source": [
    "ML models typically provide a single prediction of the most likely outcomes. You can also get probability-like scores (values from 0 to 1) from these models, but they are not true probabilities. If the model gives you a score of 0.6, that means it is more likely than a prediction of 0.5, and less likely than 0.7. However, it does not mean that in a large sample your prediction would be right 60 times out of 100. To get calibrated probabilities from our models, we have to apply additional steps. We can also get a set of predictions from models rather than a single prediction, which reflects the model's true uncertainty using a technique called conformal predictions. Read more about conformal prediction for geospatial machine learning in this amazing paper:\n",
    "\n",
    "[Singh, G., Moncrieff, G., Venter, Z., Cawse-Nicholson, K., Slingsby, J., & Robinson, T. B. (2024). Uncertainty quantification for probabilistic machine learning in earth observation using conformal prediction. Scientific Reports, 14(1), 16166.](https://www.nature.com/articles/s41598-024-65954-w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e7ad3a-5549-45f6-b2a7-d301c2993366",
   "metadata": {},
   "source": [
    "### Additional steps in the BioSCape Workshop Tutorial\n",
    "For the length of this workshop, we cannot cover all steps that were part of a 3-day BioSCape Cape Town Workshop.  Links are provided here:\n",
    "\n",
    "**`8.2.1.8. Interpret and understand ML model`**\n",
    "\n",
    "- https://ornldaac.github.io/bioscape_workshop_sa/tutorials/Machine_Learning/Invasive_AVIRIS.html#interpret-and-understand-ml-model\n",
    "\n",
    "### Final steps of the full ML classification are time intensive and are not described in this workshop.  \n",
    "\n",
    "Steps in BioSCape Cape Town Workshop Tutorial\n",
    "\n",
    "[``8.2.1.10. Merge and mosaic results``](https://ornldaac.github.io/bioscape_workshop_sa/tutorials/Machine_Learning/Invasive_AVIRIS.html#merge-and-mosaic-results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a205f922-6cbc-4da0-91fc-75723694b5b3",
   "metadata": {},
   "source": [
    "### CREDITS:  \n",
    "\n",
    "Find all of the October 2025 BioSCape Data Workshop Materials/Notebooks\n",
    "\n",
    "- https://ornldaac.github.io/bioscape_workshop_sa/intro.html\n",
    "\n",
    "This Notebook is an adaption of **Glenn Moncrieff**'s BioSCape Data Workshop Notebook:  [**Mapping invasive species using supervised machine learning and AVIRIS-NG**](https://ornldaac.github.io/bioscape_workshop_sa/tutorials/Machine_Learning/Invasive_AVIRIS.html)\n",
    "- This Notebook accesses and uses an updated version of AVIRIS-NG data with improved corrections and that are in netCDF file formats\n",
    "\n",
    "Glenn's lesson borrowed from:\n",
    "\n",
    "- [``Land cover mapping example on Microsoft Planetary Computer``](https://planetarycomputer.microsoft.com/docs/tutorials/landcover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013472a8-9f07-449a-966c-280d989ae060",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
